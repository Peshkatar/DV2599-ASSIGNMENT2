{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b49356d-f6c9-4877-bc94-1284a9fc5ec2",
   "metadata": {},
   "source": [
    "**DVAMI20h**\n",
    "\n",
    "- Arlind Iseni\n",
    "- Alexander Jamal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e76-669d-4a07-bec4-fac228db35bf",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "The aim of Assignment 2 is to experimentally compare the computational and predictive performance of three learning algorithms on a spam detection task.\n",
    "\n",
    "**Group assignment:** Max 2 students\n",
    "\n",
    "**Prerequisite reading:** sections 12.1 - 12.3 in the main literature\n",
    "\n",
    "**Language:** Python (Already implemented supervised learning algorithms and standard libraries can be used. However, It is NOT permitted to use any library or API that directly computes the Friedman and Nemeyi tests.)\n",
    "\n",
    "**Data:** Spambase Dataset, https://archive.ics.uci.edu/ml/datasets/SpambaseLinks to an external site.\n",
    "\n",
    "**Algorithms**  \n",
    "three supervised classification learning algorithms of your choice.\n",
    "\n",
    "**Evaluation measures:** perform a comparison between the selected algorithms based on 1) computational performance in terms of training time, 2) predictive performance based on accuracy, and 3) predictive performance based on F-measure.\n",
    "\n",
    "**Procedure**  \n",
    "(repeat steps 2, 3, and 4 for each evaluation measure above)\n",
    "\n",
    "1. Run stratified ten-fold cross-validation tests.\n",
    "2. Present the results exactly as in the table in example 12.4 of the main literature.\n",
    "3. Conduct the Friedman test and report the results exactly as in the table in example 12.8 of the main literature.\n",
    "4. Determine whether the average ranks as a whole display significant differences on the 0.05 alpha level and, if so, use the Nemeyi test to calculate the critical difference in order to determine which algorithms perform significantly different from each other.\n",
    "\n",
    "**Compute**  \n",
    "the size of possible instances\n",
    "the size of hypothesis space (the number of possible extensions)\n",
    "the number of possible conjunctive concepts according to the descriptions in Section 4.1 of the main literature\n",
    "Implement the algorithm and verify that it works as expected.\n",
    "Compute the accuracy of the model and report the generated model, i.e., the conjunctive rule.\n",
    "\n",
    "**Written report**  \n",
    "Template: The IEEE conference template and citation style should be followed (templatesLinks to an external site. in MS word and LaTeX).\n",
    "Language: English without spelling mistakes.\n",
    "Style: Clear.\n",
    "Content: The report should give an overview of the conducted experiments and the obtained results. It should contain (but not be limited to) information about the used classifiers, a brief description of the Friedman and Nemeyi tests along with the formulas, results of the experiment as stated above, results of the comparison stating whether the algorithms perform significantly different or not from each other for each performance measure.\n",
    "Format: PDF.\n",
    "Page limit: 2 pages excluding references (no abstract should be included)\n",
    "\n",
    "**Code**   \n",
    "Provide meaningful comments for different blocks of the code. \n",
    "A README.TXT file must clearly state exactly how to execute the code and any necessary setups.\n",
    "\n",
    "**Submission**  \n",
    "Make sure to include your names in the report and the code.\n",
    "The report must be submitted as a PDF separately (not to be included in the ZIP file).\n",
    "Code and additional files related to implementation must be archived using ZIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985dd59-2b86-46d6-94ba-94f613d4f293",
   "metadata": {},
   "source": [
    "### Import modules and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99e40aef-5213-461c-bcce-e105ae68f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abcc5e4-52de-4050-bb71-5af419d1395b",
   "metadata": {},
   "source": [
    "### Configure settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797a48a9-0db8-46f9-bbf9-a1d6027f0543",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 12)\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60608430-7ecf-4013-a20b-338b91e0ac03",
   "metadata": {},
   "source": [
    "### Load and read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad5e1b6-f3fa-4f0e-87b2-19d123818e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/spambase.data\", names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "349ffe1b-45b5-4dae-822e-905ed44ecc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_orders</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_orders  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0              0.00            0.00  ...         0.00        0.000   \n",
       "1              0.00            0.94  ...         0.00        0.132   \n",
       "2              0.64            0.25  ...         0.01        0.143   \n",
       "3              0.31            0.63  ...         0.00        0.137   \n",
       "4              0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$   char_freq_#  \\\n",
       "0          0.0        0.778         0.000        0.000   \n",
       "1          0.0        0.372         0.180        0.048   \n",
       "2          0.0        0.276         0.184        0.010   \n",
       "3          0.0        0.137         0.000        0.000   \n",
       "4          0.0        0.135         0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                       278        1  \n",
       "1                      1028        1  \n",
       "2                      2259        1  \n",
       "3                       191        1  \n",
       "4                       191        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351ca63-5676-4ac0-ade7-ad661d9ad60d",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37f72be7-da99-481b-941f-fa3ace9725de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf82d162-8790-43db-ab53-d86078153ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
