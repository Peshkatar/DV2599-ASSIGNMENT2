{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b49356d-f6c9-4877-bc94-1284a9fc5ec2",
   "metadata": {},
   "source": [
    "**DVAMI20h**\n",
    "\n",
    "- Arlind Iseni\n",
    "- Alexander Jamal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340a14a-4c0c-490c-94f8-6b9aed85f741",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assignment 2\n",
    "The aim of Assignment 2 is to experimentally compare the computational and predictive performance of three learning algorithms on a spam detection task.\n",
    "\n",
    "**Group assignment:** Max 2 students\n",
    "\n",
    "**Prerequisite reading:** sections 12.1 - 12.3 in the main literature\n",
    "\n",
    "**Language:** Python (Already implemented supervised learning algorithms and standard libraries can be used. However, It is NOT permitted to use any library or API that directly computes the Friedman and Nemeyi tests.)\n",
    "\n",
    "**Data:** Spambase Dataset, https://archive.ics.uci.edu/ml/datasets/SpambaseLinks to an external site.\n",
    "\n",
    "**Algorithms**  \n",
    "three supervised classification learning algorithms of your choice.\n",
    "\n",
    "**Evaluation measures:** perform a comparison between the selected algorithms based on 1) computational performance in terms of training time, 2) predictive performance based on accuracy, and 3) predictive performance based on F-measure.\n",
    "\n",
    "**Procedure**  \n",
    "(repeat steps 2, 3, and 4 for each evaluation measure above)\n",
    "\n",
    "1. Run stratified ten-fold cross-validation tests.\n",
    "2. Present the results exactly as in the table in example 12.4 of the main literature.\n",
    "3. Conduct the ***Friedman test*** and report the results exactly as in the table in example 12.8 of the main literature.\n",
    "4. Determine whether the average ranks as a whole display significant differences on the **0.05** $\\alpha$-level and, if so, use the Nemeyi test to calculate the critical difference in order to determine which algorithms perform significantly different from each other.\n",
    "\n",
    "**Compute**  \n",
    "the size of possible instances\n",
    "the size of hypothesis space (the number of possible extensions)\n",
    "the number of possible conjunctive concepts according to the descriptions in Section 4.1 of the main literature\n",
    "Implement the algorithm and verify that it works as expected.\n",
    "Compute the accuracy of the model and report the generated model, i.e., the conjunctive rule.\n",
    "\n",
    "**Written report**  \n",
    "Template: The IEEE conference template and citation style should be followed (templatesLinks to an external site. in MS word and LaTeX).\n",
    "Language: English without spelling mistakes.\n",
    "Style: Clear.\n",
    "Content: The report should give an overview of the conducted experiments and the obtained results. It should contain (but not be limited to) information about the used classifiers, a brief description of the Friedman and Nemeyi tests along with the formulas, results of the experiment as stated above, results of the comparison stating whether the algorithms perform significantly different or not from each other for each performance measure.\n",
    "Format: PDF.\n",
    "Page limit: 2 pages excluding references (no abstract should be included)\n",
    "\n",
    "**Code**   \n",
    "Provide meaningful comments for different blocks of the code. \n",
    "A README.TXT file must clearly state exactly how to execute the code and any necessary setups.\n",
    "\n",
    "**Submission**  \n",
    "Make sure to include your names in the report and the code.\n",
    "The report must be submitted as a PDF separately (not to be included in the ZIP file).\n",
    "Code and additional files related to implementation must be archived using ZIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985dd59-2b86-46d6-94ba-94f613d4f293",
   "metadata": {},
   "source": [
    "### Import modules and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99e40aef-5213-461c-bcce-e105ae68f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60608430-7ecf-4013-a20b-338b91e0ac03",
   "metadata": {},
   "source": [
    "### Load and read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09436610-5bbf-4d98-86b1-d0d9cf155969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns are saved in the data/names.txt file. all entries without the newline character in a list.\n",
    "with open(\"data/names.txt\", \"r\") as f:\n",
    "    columns = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ad5e1b6-f3fa-4f0e-87b2-19d123818e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/spambase.data\", names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "349ffe1b-45b5-4dae-822e-905ed44ecc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_orders</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_orders  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0              0.00            0.00  ...         0.00        0.000   \n",
       "1              0.00            0.94  ...         0.00        0.132   \n",
       "2              0.64            0.25  ...         0.01        0.143   \n",
       "3              0.31            0.63  ...         0.00        0.137   \n",
       "4              0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$   char_freq_#  \\\n",
       "0          0.0        0.778         0.000        0.000   \n",
       "1          0.0        0.372         0.180        0.048   \n",
       "2          0.0        0.276         0.184        0.010   \n",
       "3          0.0        0.137         0.000        0.000   \n",
       "4          0.0        0.135         0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                       278        1  \n",
       "1                      1028        1  \n",
       "2                      2259        1  \n",
       "3                       191        1  \n",
       "4                       191        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a0b8d-0391-4eae-8463-96e8c405bd9a",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "affc2fc3-7e87-4b48-87d3-e798503566b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.605955\n",
       "1    0.394045\n",
       "Name: is_spam, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of spam and non spam in data set\n",
    "df[\"is_spam\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ead7d-8cda-4c0d-a2c4-777613c04e5f",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efbc4ece-4f68-48d9-a18b-a75961b8a773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if any missing values\n",
    "df.isna().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eccd59bf-bc66-45ea-a98a-c101ed92a49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if there exists duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ad7b7cd-2192-4674-921d-96fef53a54db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if there exists any values below zero (errors)\n",
    "(df < 0).all().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ade15-4056-4295-a9c1-e6eafd044931",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4558e9eb-aeea-40a9-93e6-0de9fb6449db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_: pd.DataFrame, params: dict) -> KBinsDiscretizer:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Fits an algorithm to data.\n",
    "    \n",
    "    Args:\n",
    "        X_: pandas dataframe (unlabeled data).\n",
    "        params: parameters used to initialize transformer function.\n",
    "    \n",
    "    Returns:\n",
    "        Returns transformation function object.\n",
    "    \"\"\"\n",
    "    return KBinsDiscretizer(**params).fit(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86f8bf00-af56-4269-8abc-d9d0511bbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretizer(X_: pd.DataFrame, fitter_: KBinsDiscretizer) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Transforms dataframe.\n",
    "    \n",
    "    Args:\n",
    "        X_: pandas data frame (unlabeled data).\n",
    "        fitter_: KBinsDiscretizer object we use to transform our data.\n",
    "    \n",
    "    Returns:\n",
    "        Returns pandas dataframe.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(fitter_.transform(X_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351ca63-5676-4ac0-ade7-ad661d9ad60d",
   "metadata": {},
   "source": [
    "### Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37f72be7-da99-481b-941f-fa3ace9725de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into target (label, Y) and non-target (X)\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45e59b0c-289d-4cee-8f68-8837cff5f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_: pd.DataFrame, y_: pd.Series, clf, metric, params=None) -> list[float]:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Loops through k folds (balanced) and trains and tests classifier.\n",
    "    \n",
    "    Args:\n",
    "        X_: pandas data frame (unlabeled data).\n",
    "        y_: pandas series (label data).\n",
    "        clf: machine learning classifier.\n",
    "        metric: performance function.\n",
    "        params: dictionary with arguments for the transformer.\n",
    "    \n",
    "    Returns:\n",
    "        List of values for a given metric.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    metric_lst = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_, y_):\n",
    "        params = {} if params == None else params\n",
    "        \n",
    "        fitter = None if params == {} else fit(X_.iloc[train_index], params)\n",
    "        X_train = X_.iloc[train_index] if fitter == None else discretizer(X_.iloc[train_index], fitter)\n",
    "        X_test = X_.iloc[test_index] if fitter == None else discretizer(X_.iloc[test_index], fitter)\n",
    "        y_train, y_test = y_[train_index], y_[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        metric_lst.append(metric(y_test, y_pred))\n",
    "        \n",
    "    return metric_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eba75b-83d3-4467-82b8-5670280e71e7",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da15d1-228a-4c05-82fa-eb40b229f3c3",
   "metadata": {},
   "source": [
    "https://medium.com/mlearning-ai/comparing-classifiers-friedman-and-nemenyi-tests-32294103ee12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c54136a-3afa-40c8-b4f9-293226558bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation\n",
    "svm = SVC()\n",
    "ada = AdaBoostClassifier()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceda9a73-72f9-45d7-a8c8-9d22ce272165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom module for friedman table\n",
    "from friedman_table import Friedman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6980895-c64d-44ad-b916-aea9d6d47b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples\n",
    "blocks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c7bf7a8-1d87-4f7a-8b11-78e8fa0318af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatment group with accuracy\n",
    "treatments_accuracy = {\n",
    "    \"Support Vector Machine\": train_test(X, y, svm, accuracy_score, params=dict(n_bins=7, encode=\"ordinal\", strategy=\"kmeans\")), \n",
    "    \"AdaBoost\": train_test(X, y, ada, accuracy_score),\n",
    "    \"Random Forest\": train_test(X, y, rf, accuracy_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f244e91-5da8-4652-ab7d-3fc4d15037c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Friedman(blocks, treatments_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d300ce-1eb4-4f1b-8685-deeac413c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatment group with f1-score\n",
    "treatments_f1 = {\n",
    "    \"Support Vector Machine\": train_test(X, y, svm, f1_score, params=dict(n_bins=7, encode=\"ordinal\", strategy=\"kmeans\")), \n",
    "    \"AdaBoost\": train_test(X, y, ada, f1_score),\n",
    "    \"Random Forest\": train_test(X, y, rf, f1_score)}                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63851c44-d962-48ec-9fa4-68f51de3248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = Friedman(blocks, treatments_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79e3eadb-85f4-4c38-9c9a-18cb7e2be28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9240780911062907 (3.0)</td>\n",
       "      <td>0.9392624728850325 (2.0)</td>\n",
       "      <td>0.9414316702819957 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9326086956521739 (3.0)</td>\n",
       "      <td>0.95 (1.0)</td>\n",
       "      <td>0.9456521739130435 (2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9282608695652174 (3.0)</td>\n",
       "      <td>0.9369565217391305 (1.0)</td>\n",
       "      <td>0.9326086956521739 (2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9434782608695652 (2.0)</td>\n",
       "      <td>0.9369565217391305 (3.0)</td>\n",
       "      <td>0.9478260869565217 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9434782608695652 (3.0)</td>\n",
       "      <td>0.9565217391304348 (2.0)</td>\n",
       "      <td>0.9608695652173913 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9456521739130435 (3.0)</td>\n",
       "      <td>0.9478260869565217 (2.0)</td>\n",
       "      <td>0.9543478260869566 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.95 (2.0)</td>\n",
       "      <td>0.9456521739130435 (3.0)</td>\n",
       "      <td>0.9695652173913043 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9456521739130435 (3.0)</td>\n",
       "      <td>0.9652173913043478 (2.0)</td>\n",
       "      <td>0.9717391304347827 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8934782608695652 (2.0)</td>\n",
       "      <td>0.8456521739130435 (3.0)</td>\n",
       "      <td>0.8934782608695652 (2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8760869565217392 (1.0)</td>\n",
       "      <td>0.8565217391304348 (3.0)</td>\n",
       "      <td>0.8565217391304348 (3.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.9282773743280204 (2.0)</td>\n",
       "      <td>0.9280566820711119 (3.0)</td>\n",
       "      <td>0.9374040365934169 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.02347122982569813 (3.0)</td>\n",
       "      <td>0.03945231647801676 (1.0)</td>\n",
       "      <td>0.03426113118700669 (2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average rank</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Support Vector Machine                   AdaBoost  \\\n",
       "1              0.9240780911062907 (3.0)   0.9392624728850325 (2.0)   \n",
       "2              0.9326086956521739 (3.0)                 0.95 (1.0)   \n",
       "3              0.9282608695652174 (3.0)   0.9369565217391305 (1.0)   \n",
       "4              0.9434782608695652 (2.0)   0.9369565217391305 (3.0)   \n",
       "5              0.9434782608695652 (3.0)   0.9565217391304348 (2.0)   \n",
       "6              0.9456521739130435 (3.0)   0.9478260869565217 (2.0)   \n",
       "7                            0.95 (2.0)   0.9456521739130435 (3.0)   \n",
       "8              0.9456521739130435 (3.0)   0.9652173913043478 (2.0)   \n",
       "9              0.8934782608695652 (2.0)   0.8456521739130435 (3.0)   \n",
       "10             0.8760869565217392 (1.0)   0.8565217391304348 (3.0)   \n",
       "Average        0.9282773743280204 (2.0)   0.9280566820711119 (3.0)   \n",
       "Std           0.02347122982569813 (3.0)  0.03945231647801676 (1.0)   \n",
       "Average rank                        2.5                        2.2   \n",
       "\n",
       "                          Random Forest  \n",
       "1              0.9414316702819957 (1.0)  \n",
       "2              0.9456521739130435 (2.0)  \n",
       "3              0.9326086956521739 (2.0)  \n",
       "4              0.9478260869565217 (1.0)  \n",
       "5              0.9608695652173913 (1.0)  \n",
       "6              0.9543478260869566 (1.0)  \n",
       "7              0.9695652173913043 (1.0)  \n",
       "8              0.9717391304347827 (1.0)  \n",
       "9              0.8934782608695652 (2.0)  \n",
       "10             0.8565217391304348 (3.0)  \n",
       "Average        0.9374040365934169 (1.0)  \n",
       "Std           0.03426113118700669 (2.0)  \n",
       "Average rank                        1.5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85f743a1-eb97-4227-9c20-8a77cfe25d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9014084507042254 (3.0)</td>\n",
       "      <td>0.9199999999999999 (2.0)</td>\n",
       "      <td>0.9408450704225353 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9131652661064426 (3.0)</td>\n",
       "      <td>0.9362880886426593 (1.0)</td>\n",
       "      <td>0.9329608938547486 (2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9065155807365438 (3.0)</td>\n",
       "      <td>0.9169054441260746 (1.0)</td>\n",
       "      <td>0.9132947976878613 (2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9257142857142856 (2.0)</td>\n",
       "      <td>0.9196675900277009 (3.0)</td>\n",
       "      <td>0.934844192634561 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9265536723163841 (3.0)</td>\n",
       "      <td>0.943502824858757 (2.0)</td>\n",
       "      <td>0.952112676056338 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9322493224932249 (3.0)</td>\n",
       "      <td>0.9361702127659575 (2.0)</td>\n",
       "      <td>0.9450549450549451 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9329446064139941 (2.0)</td>\n",
       "      <td>0.9283667621776505 (3.0)</td>\n",
       "      <td>0.9458689458689459 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9283667621776505 (3.0)</td>\n",
       "      <td>0.956043956043956 (2.0)</td>\n",
       "      <td>0.9664804469273743 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8650137741046833 (2.0)</td>\n",
       "      <td>0.8202531645569621 (3.0)</td>\n",
       "      <td>0.8720626631853786 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.835734870317003 (1.0)</td>\n",
       "      <td>0.8156424581005587 (3.0)</td>\n",
       "      <td>0.8232044198895029 (2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.9067666591084438 (3.0)</td>\n",
       "      <td>0.9092840501300277 (2.0)</td>\n",
       "      <td>0.9226729051582192 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.030676192708378933 (3.0)</td>\n",
       "      <td>0.04706339188157599 (1.0)</td>\n",
       "      <td>0.041173229695465344 (2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average rank</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Support Vector Machine                   AdaBoost  \\\n",
       "1               0.9014084507042254 (3.0)   0.9199999999999999 (2.0)   \n",
       "2               0.9131652661064426 (3.0)   0.9362880886426593 (1.0)   \n",
       "3               0.9065155807365438 (3.0)   0.9169054441260746 (1.0)   \n",
       "4               0.9257142857142856 (2.0)   0.9196675900277009 (3.0)   \n",
       "5               0.9265536723163841 (3.0)    0.943502824858757 (2.0)   \n",
       "6               0.9322493224932249 (3.0)   0.9361702127659575 (2.0)   \n",
       "7               0.9329446064139941 (2.0)   0.9283667621776505 (3.0)   \n",
       "8               0.9283667621776505 (3.0)    0.956043956043956 (2.0)   \n",
       "9               0.8650137741046833 (2.0)   0.8202531645569621 (3.0)   \n",
       "10               0.835734870317003 (1.0)   0.8156424581005587 (3.0)   \n",
       "Average         0.9067666591084438 (3.0)   0.9092840501300277 (2.0)   \n",
       "Std           0.030676192708378933 (3.0)  0.04706339188157599 (1.0)   \n",
       "Average rank                         2.5                        2.2   \n",
       "\n",
       "                           Random Forest  \n",
       "1               0.9408450704225353 (1.0)  \n",
       "2               0.9329608938547486 (2.0)  \n",
       "3               0.9132947976878613 (2.0)  \n",
       "4                0.934844192634561 (1.0)  \n",
       "5                0.952112676056338 (1.0)  \n",
       "6               0.9450549450549451 (1.0)  \n",
       "7               0.9458689458689459 (1.0)  \n",
       "8               0.9664804469273743 (1.0)  \n",
       "9               0.8720626631853786 (1.0)  \n",
       "10              0.8232044198895029 (2.0)  \n",
       "Average         0.9226729051582192 (1.0)  \n",
       "Std           0.041173229695465344 (2.0)  \n",
       "Average rank                         1.3  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985db06-6533-4511-87a5-e0af8cb9d847",
   "metadata": {},
   "source": [
    "### Nemenyi test\n",
    "\n",
    "In order to conduct the ***Nemenyi*** test on the 3 algorithms we have, we will be calculating the mean value of the rankings of each algorithm which has been done in *f1*.\n",
    "\n",
    "We continue by calculating the critical distance (CD) using the following formula: CD = q\\$_\\alpha \\times \\sqrt{\\frac{k \\times (k+1)}{6n}}$\n",
    "\n",
    "where $q_\\alpha$ depends on the significance level $\\alpha$ as well as **k**: for $\\alpha$ = 0.05 and **k** = 3 it is X, **n** is the amount of measurements taken which in our case is **n** = 10, which leads to a **CD** of X. Since our average ranks for Support Vector Machine, AdaBoost and Random Forest are *X1, X2 and X3* respectively, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf6852f4-768e-4ab2-aaba-33d9a6ce5acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2199986885238854"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.nemenyi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26ae55e8-1fe7-4ce3-8f6a-2a04a3759f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2199986885238854"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.nemenyi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701f26d4-006c-42cc-ae08-1c9801145780",
   "metadata": {},
   "source": [
    "Support Vector machine and Ada Boost both pass the critical distance-threshold and therefore our null hypothesis is rejected (not any significant differences between treatments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
