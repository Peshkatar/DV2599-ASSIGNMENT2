{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b49356d-f6c9-4877-bc94-1284a9fc5ec2",
   "metadata": {},
   "source": [
    "**DVAMI20h**\n",
    "\n",
    "- Arlind Iseni\n",
    "- Alexander Jamal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e76-669d-4a07-bec4-fac228db35bf",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "The aim of Assignment 2 is to experimentally compare the computational and predictive performance of three learning algorithms on a spam detection task.\n",
    "\n",
    "**Group assignment:** Max 2 students\n",
    "\n",
    "**Prerequisite reading:** sections 12.1 - 12.3 in the main literature\n",
    "\n",
    "**Language:** Python (Already implemented supervised learning algorithms and standard libraries can be used. However, It is NOT permitted to use any library or API that directly computes the Friedman and Nemeyi tests.)\n",
    "\n",
    "**Data:** Spambase Dataset, https://archive.ics.uci.edu/ml/datasets/SpambaseLinks to an external site.\n",
    "\n",
    "**Algorithms**  \n",
    "three supervised classification learning algorithms of your choice.\n",
    "\n",
    "**Evaluation measures:** perform a comparison between the selected algorithms based on 1) computational performance in terms of training time, 2) predictive performance based on accuracy, and 3) predictive performance based on F-measure.\n",
    "\n",
    "**Procedure**  \n",
    "(repeat steps 2, 3, and 4 for each evaluation measure above)\n",
    "\n",
    "1. Run stratified ten-fold cross-validation tests.\n",
    "2. Present the results exactly as in the table in example 12.4 of the main literature.\n",
    "3. Conduct the Friedman test and report the results exactly as in the table in example 12.8 of the main literature.\n",
    "4. Determine whether the average ranks as a whole display significant differences on the 0.05 alpha level and, if so, use the Nemeyi test to calculate the critical difference in order to determine which algorithms perform significantly different from each other.\n",
    "\n",
    "**Compute**  \n",
    "the size of possible instances\n",
    "the size of hypothesis space (the number of possible extensions)\n",
    "the number of possible conjunctive concepts according to the descriptions in Section 4.1 of the main literature\n",
    "Implement the algorithm and verify that it works as expected.\n",
    "Compute the accuracy of the model and report the generated model, i.e., the conjunctive rule.\n",
    "\n",
    "**Written report**  \n",
    "Template: The IEEE conference template and citation style should be followed (templatesLinks to an external site. in MS word and LaTeX).\n",
    "Language: English without spelling mistakes.\n",
    "Style: Clear.\n",
    "Content: The report should give an overview of the conducted experiments and the obtained results. It should contain (but not be limited to) information about the used classifiers, a brief description of the Friedman and Nemeyi tests along with the formulas, results of the experiment as stated above, results of the comparison stating whether the algorithms perform significantly different or not from each other for each performance measure.\n",
    "Format: PDF.\n",
    "Page limit: 2 pages excluding references (no abstract should be included)\n",
    "\n",
    "**Code**   \n",
    "Provide meaningful comments for different blocks of the code. \n",
    "A README.TXT file must clearly state exactly how to execute the code and any necessary setups.\n",
    "\n",
    "**Submission**  \n",
    "Make sure to include your names in the report and the code.\n",
    "The report must be submitted as a PDF separately (not to be included in the ZIP file).\n",
    "Code and additional files related to implementation must be archived using ZIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985dd59-2b86-46d6-94ba-94f613d4f293",
   "metadata": {},
   "source": [
    "### Import modules and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99e40aef-5213-461c-bcce-e105ae68f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abcc5e4-52de-4050-bb71-5af419d1395b",
   "metadata": {},
   "source": [
    "### Configure settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797a48a9-0db8-46f9-bbf9-a1d6027f0543",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 12)\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60608430-7ecf-4013-a20b-338b91e0ac03",
   "metadata": {},
   "source": [
    "### Load and read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09436610-5bbf-4d98-86b1-d0d9cf155969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns are saved in the data/names.txt file. Here we all entries without the newline character in a list.\n",
    "with open(\"data/names.txt\", \"r\") as f:\n",
    "    columns = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad5e1b6-f3fa-4f0e-87b2-19d123818e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/spambase.data\", names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349ffe1b-45b5-4dae-822e-905ed44ecc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_orders</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_orders  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0              0.00            0.00  ...         0.00        0.000   \n",
       "1              0.00            0.94  ...         0.00        0.132   \n",
       "2              0.64            0.25  ...         0.01        0.143   \n",
       "3              0.31            0.63  ...         0.00        0.137   \n",
       "4              0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$   char_freq_#  \\\n",
       "0          0.0        0.778         0.000        0.000   \n",
       "1          0.0        0.372         0.180        0.048   \n",
       "2          0.0        0.276         0.184        0.010   \n",
       "3          0.0        0.137         0.000        0.000   \n",
       "4          0.0        0.135         0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                       278        1  \n",
       "1                      1028        1  \n",
       "2                      2259        1  \n",
       "3                       191        1  \n",
       "4                       191        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ead7d-8cda-4c0d-a2c4-777613c04e5f",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a952c558-eca5-48c3-9cfd-060257ca631b",
   "metadata": {},
   "source": [
    "#### null-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbc4ece-4f68-48d9-a18b-a75961b8a773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0b59b-2656-4eb6-8241-85834b8bfb33",
   "metadata": {},
   "source": [
    "#### duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eccd59bf-bc66-45ea-a98a-c101ed92a49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d017de-9668-4c6e-82dd-161ac1451c29",
   "metadata": {},
   "source": [
    "#### negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ad7b7cd-2192-4674-921d-96fef53a54db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df < 0).all().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a9067-2310-47c9-8ea1-994037f2181b",
   "metadata": {},
   "source": [
    "#### Size reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b895a8f1-c302-44ab-a6e5-6eb5cb8d22e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                float64\n",
       "word_freq_address             float64\n",
       "word_freq_all                 float64\n",
       "word_freq_3d                  float64\n",
       "word_freq_our                 float64\n",
       "word_freq_over                float64\n",
       "word_freq_remove              float64\n",
       "word_freq_internet            float64\n",
       "word_freq_orders              float64\n",
       "word_freq_mail                float64\n",
       "word_freq_receive             float64\n",
       "word_freq_will                float64\n",
       "word_freq_people              float64\n",
       "word_freq_report              float64\n",
       "word_freq_addresses           float64\n",
       "word_freq_free                float64\n",
       "word_freq_business            float64\n",
       "word_freq_email               float64\n",
       "word_freq_you                 float64\n",
       "word_freq_credit              float64\n",
       "word_freq_your                float64\n",
       "word_freq_font                float64\n",
       "word_freq_000                 float64\n",
       "word_freq_money               float64\n",
       "word_freq_hp                  float64\n",
       "word_freq_hpl                 float64\n",
       "word_freq_george              float64\n",
       "word_freq_650                 float64\n",
       "word_freq_lab                 float64\n",
       "word_freq_labs                float64\n",
       "word_freq_telnet              float64\n",
       "word_freq_857                 float64\n",
       "word_freq_data                float64\n",
       "word_freq_415                 float64\n",
       "word_freq_85                  float64\n",
       "word_freq_technology          float64\n",
       "word_freq_1999                float64\n",
       "word_freq_parts               float64\n",
       "word_freq_pm                  float64\n",
       "word_freq_direct              float64\n",
       "word_freq_cs                  float64\n",
       "word_freq_meeting             float64\n",
       "word_freq_original            float64\n",
       "word_freq_project             float64\n",
       "word_freq_re                  float64\n",
       "word_freq_edu                 float64\n",
       "word_freq_table               float64\n",
       "word_freq_conference          float64\n",
       "char_freq_;                   float64\n",
       "char_freq_(                   float64\n",
       "char_freq_[                   float64\n",
       "char_freq_!                   float64\n",
       "char_freq_$                   float64\n",
       "char_freq_#                   float64\n",
       "capital_run_length_average    float64\n",
       "capital_run_length_longest      int64\n",
       "capital_run_length_total        int64\n",
       "is_spam                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351ca63-5676-4ac0-ade7-ad661d9ad60d",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37f72be7-da99-481b-941f-fa3ace9725de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf82d162-8790-43db-ab53-d86078153ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4b6824fd-1607-41eb-9288-56cf8890b639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3680, 57), (921, 57), (3680,), (921,))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ade15-4056-4295-a9c1-e6eafd044931",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6338835f-28b3-4e1b-8e20-e03d8c2fc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretization(X: pd.DataFrame, nbins: int, method: str, columns_: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"discretizes dataframe into n_bins, joins the class column post-discretization and lastly converts the table data type into 8-bit integer.\"\"\"\n",
    "    return (\n",
    "        pd\n",
    "        .DataFrame(\n",
    "            KBinsDiscretizer(n_bins=nbins, encode=\"ordinal\", strategy=method)\n",
    "           .fit_transform(X),\n",
    "            columns=columns_\n",
    "        )\n",
    "        .astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0eb2ea91-3347-4ec8-ad09-823e03f79fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_disc = (\n",
    "    discretization(\n",
    "        X=X_train, \n",
    "        method=\"uniform\",\n",
    "        nbins=10, \n",
    "        columns_=columns[:-1]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9f662ed2-5df2-4efe-a172-2aadf25e2c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_orders</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0                  0              2             0   \n",
       "1               0                  0              0             0   \n",
       "2               0                  0              0             0   \n",
       "3               0                  0              0             0   \n",
       "4               0                  0              1             0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0               0                 0                   0   \n",
       "1              0               0                 0                   0   \n",
       "2              0               0                 0                   0   \n",
       "3              0               0                 0                   0   \n",
       "4              0               0                 0                   0   \n",
       "\n",
       "   word_freq_orders  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "0                 0               0  ...                     0            0   \n",
       "1                 0               0  ...                     0            0   \n",
       "2                 1               0  ...                     0            0   \n",
       "3                 0               0  ...                     0            0   \n",
       "4                 0               0  ...                     0            0   \n",
       "\n",
       "   char_freq_(  char_freq_[  char_freq_!  char_freq_$   char_freq_#  \\\n",
       "0            0            0            0             0            0   \n",
       "1            0            0            0             0            0   \n",
       "2            0            0            0             0            0   \n",
       "3            0            0            0             0            0   \n",
       "4            0            0            0             0            0   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_disc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea4927-18cf-4514-aea4-e6fa5135a645",
   "metadata": {},
   "source": [
    "### Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6c54136a-3afa-40c8-b4f9-293226558bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db3b86d6-9ff0-486e-8833-e9268b5dc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = SVC().fit(X_disc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f26d1742-bca0-4320-9ca8-0f3a92bbfabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7198697068403909, 0.5743756786102063)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_test, y_test), clf2.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
